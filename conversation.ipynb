{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Langchain\\venv2\\lib\\site-packages\\sentence_transformers\\cross_encoder\\CrossEncoder.py:11: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from tqdm.autonotebook import tqdm, trange\n",
      "d:\\Langchain\\venv2\\lib\\site-packages\\transformers\\tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "from langchain_groq import ChatGroq\n",
    "groq_api_key = os.getenv('GROQ_API_KEY')\n",
    "llm = ChatGroq(model_name='llama-3.1-70b-versatile',groq_api_key=groq_api_key)\n",
    "os.environ['HF_TOKEN'] = os.getenv('HF_TOKEN')\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "embeddings = HuggingFaceEmbeddings(model_name='all-MiniLM-L6-v2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "USER_AGENT environment variable not set, consider setting it to identify your requests.\n"
     ]
    }
   ],
   "source": [
    "from langchain_chroma import Chroma\n",
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain.chains import create_retrieval_chain\n",
    "from langchain.chains.combine_documents import create_stuff_documents_chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'source': 'https://lilianweng.github.io/faq/', 'title': \"FAQ | Lil'Log\", 'description': \"FAQ - Lil'Log\", 'language': 'en'}, page_content='\\n\\n\\n\\n\\n\\nFAQ | Lil\\'Log\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nLil\\'Log\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nPosts\\n\\n\\n\\n\\nArchive\\n\\n\\n\\n\\nSearch\\n\\n\\n\\n\\nTags\\n\\n\\n\\n\\nFAQ\\n\\n\\n\\n\\nemojisearch.app\\n\\n\\n\\n\\n\\n\\n\\nFAQ\\n\\n\\n\\nQ: How can I get an update when a new post comes out?\\nA: I post about my new post on this Twitter @lilianweng account. There is also a RSS feed.\\n\\n\\nQ: What tool do you use for plotting?\\nA: I\\'m using Google Presentation (cloud version of PowerPoint).\\n\\n\\nQ: What if I see something incorrect in the post?\\nA: Send me an email: anotherlilian AT gmail.com if you have questions or find errors. Thanks \\uf8ffüòä! But time of one person is limited and I\\'m really busy nowadays, so there may take some time for me to get to process it.\\n\\n\\nQ: Can I translate your posts to another language?\\nA: Yes and my pleasure! But please email me in advance and please keep the original post link on top (rather than in tiny font at the end, and yes I do see that case and that makes me feel sad \\uf8ffüôÅ).\\n\\n\\nQ: Do you update your old posts?\\nA: Yes, I update my old posts periodically. Everytime I would add an one-line update message in blue on top of that post, like:\\n\\n\\n\\nQ: Hmmm ... I have papers on super relevant topics but you didn\\'t include them?\\nA: As you may know, it is pretty challenging to do a comprehensive literature review given a big topic. There are so so many papers in the wild. With Google scholar and recursive citation search, I get to see quite a lot of papers but still not all of them. You are more than welcome to shoot me an email with pointers to interesting but missing papers. Cheers!\\n\\t\\n\\n\\nQ: How can you keep up blogging?\\nA: \"Pain is inevitable but suffering is optional\" --- this is the first sentence of Haruki Murakami\\'s book \"What I Talk About When I Talk About Running\". I love that book. His altitude towards running is pretty much aligned with how I feel about maintaining this blog.\\n\\t\\n\\n\\n\\n\\n© 2024 Lil\\'Log\\n\\n        Powered by\\n        Hugo &\\n        PaperMod\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n')]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1. Load, chunk and index the contents of the blog to create a retriever.\n",
    "import bs4\n",
    "loader = WebBaseLoader(\n",
    "    web_paths=(\"https://docs.python.org/3/tutorial/controlflow.html\",),\n",
    "    bs_kwargs=dict(\n",
    "        parse_only=bs4.SoupStrainer(\n",
    "            class_=(\"post-content\", \"post-title\", \"post-header\")\n",
    "        )\n",
    "    ),\n",
    ")\n",
    "\n",
    "docs=loader.load()\n",
    "docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000,chunk_overlap=200)\n",
    "splits = text_splitter.split_documents(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Langchain\\venv2\\lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:439: UserWarning: 1Torch was not compiled with flash attention. (Triggered internally at C:\\cb\\pytorch_1000000000000\\work\\aten\\src\\ATen\\native\\transformers\\cuda\\sdp_utils.cpp:555.)\n",
      "  attn_output = torch.nn.functional.scaled_dot_product_attention(\n"
     ]
    }
   ],
   "source": [
    "vector_store = Chroma.from_documents(embedding=embeddings,documents=splits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "retriver = vector_store.as_retriever()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Prompt Template\n",
    "system_prompt = (\n",
    "    \"you are AI assistant answer the question based on context\"\n",
    "    \"\\n\\n\"\n",
    "    \"{context}\"\n",
    ")\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "[\n",
    "    ('system',system_prompt),\n",
    "    ('human',\"{input}\")\n",
    "]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "## creating stufff document chain\n",
    "question_answer_chain = create_stuff_documents_chain(llm,prompt)\n",
    "\n",
    "## create retrival chain\n",
    "rag_chain = create_retrieval_chain(retriver,question_answer_chain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = rag_chain.invoke({'input':'what is self-reflection?'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Self-reflection is a vital aspect that allows autonomous agents to improve iteratively by refining past action decisions and correcting previous mistakes. It involves the agent reflecting on its own experiences, actions, and decisions to identify areas for improvement and learn from its mistakes. This self-reflection process enables the agent to refine its decision-making and problem-solving skills, leading to better performance over time.\\n\\nIn the context of the Reflexion framework, self-reflection is created by showing two-shot examples to a Large Language Model (LLM) and adding reflections into the agent's working memory. These reflections serve as context for querying the LLM and guide the agent's future behavior. Self-reflection is an essential component of the Reflexion framework, allowing the agent to learn from its experiences and adapt to new situations.\""
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response['answer']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Adding the chat history\n",
    "\n",
    "from langchain.chains import create_history_aware_retriever\n",
    "from langchain_core.prompts import MessagesPlaceholder\n",
    "\n",
    "## prompt\n",
    "contextualize_q_system_prompt = (\n",
    "    \"Given a chat history and the latest user question \"\n",
    "    \"which might reference context in the chat history, \"\n",
    "    \"formulate a standalone question which can be understood \"\n",
    "    \"without the chat history. Do NOT answer the question, \"\n",
    "    \"just reformulate it if needed and otherwise return it as is.\"\n",
    ")\n",
    "\n",
    "\n",
    "contextulize_q_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        ('system',contextualize_q_system_prompt),\n",
    "        MessagesPlaceholder('chat_history'),\n",
    "        ('human','{input}'),\n",
    "    ]\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RunnableBinding(bound=RunnableBranch(branches=[(RunnableLambda(lambda x: not x.get('chat_history', False)), RunnableLambda(lambda x: x['input'])\n",
       "| VectorStoreRetriever(tags=['Chroma', 'HuggingFaceEmbeddings'], vectorstore=<langchain_chroma.vectorstores.Chroma object at 0x000002B930D5CC70>))], default=ChatPromptTemplate(input_variables=['chat_history', 'input'], input_types={'chat_history': typing.List[typing.Union[langchain_core.messages.ai.AIMessage, langchain_core.messages.human.HumanMessage, langchain_core.messages.chat.ChatMessage, langchain_core.messages.system.SystemMessage, langchain_core.messages.function.FunctionMessage, langchain_core.messages.tool.ToolMessage]]}, messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], template='Given a chat history and the latest user question which might reference context in the chat history, formulate a standalone question which can be understood without the chat history. Do NOT answer the question, just reformulate it if needed and otherwise return it as is.')), MessagesPlaceholder(variable_name='chat_history'), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input'], template='{input}'))])\n",
       "| ChatGroq(client=<groq.resources.chat.completions.Completions object at 0x000002B93336B0D0>, async_client=<groq.resources.chat.completions.AsyncCompletions object at 0x000002B93336BD60>, model_name='llama-3.1-70b-versatile', groq_api_key=SecretStr('**********'))\n",
       "| StrOutputParser()\n",
       "| VectorStoreRetriever(tags=['Chroma', 'HuggingFaceEmbeddings'], vectorstore=<langchain_chroma.vectorstores.Chroma object at 0x000002B930D5CC70>)), config={'run_name': 'chat_retriever_chain'})"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## create aware retriver\n",
    "\n",
    "history_aware_retriver = create_history_aware_retriever(retriever=retriver,prompt=contextulize_q_prompt,llm=llm)\n",
    "\n",
    "history_aware_retriver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "qa_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", system_prompt),\n",
    "        MessagesPlaceholder(\"chat_history\"),\n",
    "        (\"human\", \"{input}\"),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "## create stuff document chain\n",
    "question_answer_chain=create_stuff_documents_chain(llm,qa_prompt)\n",
    "\n",
    "## create retrival chain\n",
    "rag_chain=create_retrieval_chain(history_aware_retriver,question_answer_chain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[HumanMessage(content='What is self-reflection'),\n",
       " AIMessage(content=\"Self-reflection, in the context of autonomous agents, is the ability to analyze and evaluate their own past actions and decisions. It allows agents to identify mistakes, refine their decision-making processes, and improve their overall performance over time.\\n\\nIn the Reflexion framework, self-reflection is created by providing the agent with examples of failed trajectories and ideal reflections that guide future changes in the plan. These reflections are stored in the agent's working memory and used as context for querying the Language Model (LLM) to inform future decisions.\\n\\nSelf-reflection plays a crucial role in real-world tasks where trial and error are inevitable, enabling agents to learn from their mistakes and adapt to changing situations. It is distinct from the reflection mechanism, which synthesizes memories into higher-level inferences over time, guiding the agent's future behavior.\\n\\nIn essence, self-reflection is a vital aspect of an agent's ability to improve iteratively, refine past action decisions, and correct previous mistakes.\")]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.messages import AIMessage,HumanMessage\n",
    "\n",
    "chat_history = []\n",
    "\n",
    "question = 'What is self-reflection'\n",
    "\n",
    "response1 = rag_chain.invoke({'input':question,'chat_history':chat_history})\n",
    "\n",
    "chat_history.extend(\n",
    "    [\n",
    "    HumanMessage(content=question),\n",
    "    AIMessage(content=response1['answer'])\n",
    "    ]\n",
    ")\n",
    "question2 = 'Tell me more about it?'\n",
    "\n",
    "response2 = rag_chain.invoke({'input':question2,'chat_history':chat_history})\n",
    "response2['answer']\n",
    "\n",
    "chat_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "## adding session_id\n",
    "\n",
    "from langchain_community.chat_message_histories import ChatMessageHistory\n",
    "from langchain_core.chat_history import BaseChatMessageHistory\n",
    "from langchain_core.runnables.history import RunnableWithMessageHistory\n",
    "\n",
    "store = {}\n",
    "\n",
    "def history_of_messages(session_id:str)->BaseChatMessageHistory:\n",
    "    if session_id not in store:\n",
    "        store[session_id] = ChatMessageHistory()\n",
    "\n",
    "    return store[session_id]\n",
    "\n",
    "conversation_rag_chain = RunnableWithMessageHistory(\n",
    "    rag_chain,\n",
    "    history_of_messages,\n",
    "    input_messages_key='input',\n",
    "    history_messages_key='chat_history',\n",
    "    output_messages_key='answer'\n",
    "    ) ## used for interactive chatbot with msg history\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Task decomposition is a process of breaking down a complex task into smaller, simpler, and manageable sub-tasks or steps. This is done to make the task more understandable, easier to execute, and to facilitate problem-solving.\\n\\nIn the context of Large Language Models (LLMs) and autonomous agent systems, task decomposition is an essential component of planning. It involves taking a complicated task and decomposing it into a series of smaller tasks that can be executed by the agent.\\n\\nTask decomposition can be done in various ways, including:\\n\\n1. **Simple prompting**: Using simple prompts, such as \"Steps for XYZ.\\\\n1.\", to ask the LLM to break down a task into smaller steps.\\n2. **Task-specific instructions**: Providing task-specific instructions, such as \"Write a story outline.\" for writing a novel, to help the LLM decompose the task.\\n3. **Human inputs**: Using human inputs, such as providing a list of sub-tasks or steps, to help the LLM decompose the task.\\n4. **Chain of thought (CoT)**: Using the CoT technique, which involves instructing the LLM to \"think step by step\" to decompose a task into smaller and simpler steps.\\n5. **Tree of Thoughts**: Exploring multiple reasoning possibilities at each step by creating a tree structure and using search algorithms, such as BFS or DFS, to evaluate the sub-tasks.\\n\\nBy decomposing a complex task into smaller sub-tasks, the LLM can better understand the task, plan its actions, and execute the task more efficiently.'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation_rag_chain.invoke(\n",
    "\n",
    "    {\"input\":\"What is task decompostion\"},\n",
    "    config={'configurable':{'session_id':'abcd'}},\n",
    ")['answer']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'You previously asked about the types of memory. According to the text, there are several types of memory in human brains:\\n\\n1. **Sensory Memory**: This is the earliest stage of memory, providing the ability to retain impressions of sensory information (visual, auditory, etc) after the original stimuli have ended. Sensory memory typically only lasts for up to a few seconds. Subcategories include:\\n\\t* **Iconic memory** (visual)\\n\\t* **Echoic memory** (auditory)\\n\\t* **Haptic memory** (touch)\\n2. **Short-Term Memory (STM) or Working Memory**: This stores information that we are currently aware of and needed to carry out complex cognitive tasks such as learning and reasoning. Short-term memory is believed to have the capacity of about 7 items and lasts for 20-30 seconds.\\n3. **Long-Term Memory (LTM)**: Long-term memory can store information for a remarkably long time, ranging from a few days to decades, with an essentially unlimited storage capacity. There are two subtypes of LTM:\\n\\t* **Explicit / Declarative memory**: This is memory of facts and events, and refers to those memories that can be consciously recalled, including episodic memory (events and experiences) and semantic memory (facts and concepts).\\n\\t* **Implicit / Procedural memory**: This type of memory is unconscious and involves skills and routines that are performed automatically, like riding a bike or typing on a keyboard.'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation_rag_chain.invoke(\n",
    "\n",
    "    {\"input\":\"What are the types of memory?\"},\n",
    "    config={'configurable':{'session_id':'abcd'}},\n",
    ")['answer']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'abcd': InMemoryChatMessageHistory(messages=[HumanMessage(content='What is task decompostion'), AIMessage(content='Task decomposition is a process of breaking down a complex task into smaller, simpler, and manageable sub-tasks or steps. This is done to make the task more understandable, easier to execute, and to facilitate problem-solving.\\n\\nIn the context of Large Language Models (LLMs) and autonomous agent systems, task decomposition is an essential component of planning. It involves taking a complicated task and decomposing it into a series of smaller tasks that can be executed by the agent.\\n\\nTask decomposition can be done in various ways, including:\\n\\n1. **Simple prompting**: Using simple prompts, such as \"Steps for XYZ.\\\\n1.\", to ask the LLM to break down a task into smaller steps.\\n2. **Task-specific instructions**: Providing task-specific instructions, such as \"Write a story outline.\" for writing a novel, to help the LLM decompose the task.\\n3. **Human inputs**: Using human inputs, such as providing a list of sub-tasks or steps, to help the LLM decompose the task.\\n4. **Chain of thought (CoT)**: Using the CoT technique, which involves instructing the LLM to \"think step by step\" to decompose a task into smaller and simpler steps.\\n5. **Tree of Thoughts**: Exploring multiple reasoning possibilities at each step by creating a tree structure and using search algorithms, such as BFS or DFS, to evaluate the sub-tasks.\\n\\nBy decomposing a complex task into smaller sub-tasks, the LLM can better understand the task, plan its actions, and execute the task more efficiently.'), HumanMessage(content='What question i previously ask ?'), AIMessage(content='You previously asked \"What is task decomposition?\"')])}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
